{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadowRaccoon/PrograConcurrente2023C1/blob/main/TP2/TP_2_Parte_3_M1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32YB71STfPcy"
      },
      "source": [
        "# **Trabajo Práctico GPU**\n",
        "\n",
        "Este ejercicio se ha optado para aplicar 2 multidimensiones en GPU. El ejemplo modifica el color de una imagen parametrizada a escala de grises. El cálculo de la escala se realiza convirtiendo los 3 canales RGB, que representan a los colores R (*rojo*)-G(*verde*)-B(*azul*), de cada pixel siguiendo la ecuación:\n",
        "\n",
        "<center>$ Pixel=R*0.30+G*0.59+B*0.11$</center>\n",
        "\n",
        "EL objetivo es enseñar el funcionamiento del Lenguaje Python, CUDA y el manejo de imágenes a bajo nivel. El ejemplo es ilustrativo, ya que internamente el módulo Pillow posee varios filtros integrados.\n",
        "\n",
        "\n",
        "---\n",
        "### **1.  Preguntas del TP**\n",
        "\n",
        "a) Analice el siguiente ejemplo, visto en clase, y mencione en que lugar se realizan las siguientes partes.\n",
        "\n",
        "*   Reservar memoria en GPU\n",
        "*   Transferir datos de la CPU a la GPU\n",
        "*   Transferir el Kernel y ejecutar el algoritmo\n",
        "*   Transferir datos de la CPU a la GPU\n",
        "*   Limpiar Memoria\n",
        "\n",
        "b)¿ Cuál es la configuración inicial(por defecto) de Grilla y Bloques con que se ejecuta el algoritmo?\n",
        "\n",
        "c) ¿Cuantos hilos se crean en total cuando se llama al kernel?\n",
        "\n",
        "**Tips**: utilice la formula dim_hilo_x*dim_bloque_x*dim_hilo_y*dim_bloque_y para calcular la cantidad de threads total\n",
        "\n",
        "d) ¿Cúantos hilos se planifican de más?\n",
        "\n",
        "**Tips:** Los que no tengan condición verdadera en la condición dentro del kernel.\n",
        "\n",
        "e) Modifique el código del Kernel, para que en lugar de aplicar escalas de grises a la imagen, aplique el filtro de inversion de colores.\n",
        "\n",
        "f) Utilice NVProf para medir la velocidad de respuesta que tiene el algoritmo durante su ejecución de acuerdo a la siguiente configuración y describa que sucede con los tiempos.\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "| Configuración de Bloque  | Tiempo de ejecución del kernel |\n",
        "| ------------- | ------------- |\n",
        "| (16,19,1)     |               |\n",
        "| (24,24,1)     |               |\n",
        "| máximo soportado por GPU          |\n",
        "\n",
        "</div>\n",
        "\n",
        "**Tips:** Para saber cual es el tamaño maximo de la configuración soportado por la GPU ejecute el siguiente comando:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git\n",
        "!cd  cuda-samples/Samples/1_Utilities/deviceQuery/; make >/dev/null\n",
        "!cuda-samples/Samples/1_Utilities/deviceQuery/deviceQuery | grep \"Max dimension\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj1gq_WjBj33",
        "outputId": "e06df18c-1291-4de4-848d-ac0690982c44"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cuda-samples' already exists and is not an empty directory.\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "g)En el punto anterior ¿Qué sucedio al medir el tiempo con máximo de Threads soportados por la GPU?\n",
        "\n",
        "h) Mida el tiempo de respuesta que tiene el algoritmo con la dimension **\"X\"** en su maxima capacidad y el resto en 1 (ej:(1024,1,1)). Luego modifique la configuración para que la dimension **\"Y\"** tenga su maxima capacidad y el resto en 1.(ej:(1,1024,1)) Compare los resultado.\n",
        "¿A que cree que se debe la diferencia de tiempo?\n",
        "\n",
        "i) ¿Qué cambios realizaría para que solo se procese la parte derecha de la imagen? ¿Qué sucede con la parte izquierda en la imagen resultante? ¿Qué sucede con la velocidad de respuesta?"
      ],
      "metadata": {
        "id": "OsgCWdYCDwP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2 Armado del ambiente\n",
        "Toma la dirección web de una imagen con acceso público en internet, la deja disponible al contexto de ejecución del cuaderno Colab."
      ],
      "metadata": {
        "id": "UerkdcqnclGn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcnL4UkAN7ub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5a0d89-66f1-4020-c6d8-db6fc6051cf3",
        "cellView": "form"
      },
      "source": [
        "#@title # 2.1 Parámetros de ejecución\n",
        "#@markdown ---\n",
        "#@markdown ### Especifique la URL de la imagen:\n",
        "url_imagen = \"https://raw.githubusercontent.com/soa-pc-unlam/ProgramacionConcurrente/main/Enunciados%20TPs/TP-GPU/MesiCopa.jpg\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "# Leo la imagen desde internet.\n",
        "#!wget https://github.com/wvaliente/SOA_HPC/blob/main/unlam.jpg?raw=true -O imagen.jpg\n",
        "\n",
        "# TODO: Mejorar informaciòn y resutlado de ejecución.\n",
        "!wget {url_imagen} -O imagen.jpg\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-18 22:08:09--  https://raw.githubusercontent.com/soa-pc-unlam/ProgramacionConcurrente/main/Enunciados%20TPs/TP-GPU/MesiCopa.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209591 (205K) [image/jpeg]\n",
            "Saving to: ‘imagen.jpg’\n",
            "\n",
            "imagen.jpg          100%[===================>] 204.68K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-06-18 22:08:09 (19.2 MB/s) - ‘imagen.jpg’ saved [209591/209591]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GLsQ34ysP4_"
      },
      "source": [
        "---\n",
        "## 2.2 Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ropgS48tsRTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6e108f-f222-4077-fd8e-45f8726d7bc5"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.2)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp310-cp310-linux_x86_64.whl size=661975 sha256=b3b4635916cb9d0f19fa11210c36ee67141fcc1ca9af79bf45c773e4aa74535b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/7b/06/82a395a243fce00035dea9914d92bbef0013401497d849f8bc\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2023.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt4Pea0Psrx_"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n",
        "Ejecución del algoritmo escala de grises en GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_uVXVJjz_Jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e035590c-793f-4954-d44d-45dd09cedd57"
      },
      "source": [
        "#Comentar esta linea para mostrar las imagenes\n",
        "%%writefile filter_image.py\n",
        "\n",
        "#Comentar esta linea para medir los tiempos\n",
        "#%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from PIL import Image\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "img_nombre = 'imagen.jpg'\n",
        "image = Image.open( img_nombre )\n",
        "\n",
        "# summarize some details about the image\n",
        "img_ancho, img_alto  = image.size\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "img_O_cpu = numpy.asarray(image)\n",
        "img_O_cpu = img_O_cpu.astype( numpy.int32() )\n",
        "img_R_cpu = numpy.empty_like( img_O_cpu)\n",
        "\n",
        "img_O_gpu = cuda.mem_alloc( img_O_cpu.nbytes )\n",
        "img_R_gpu = cuda.mem_alloc( img_R_cpu.nbytes )\n",
        "\n",
        "cuda.memcpy_htod( img_O_gpu, img_O_cpu )\n",
        "cuda.memcpy_htod( img_R_gpu, img_R_cpu )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "module = SourceModule(\"\"\"\n",
        "#define PIXEL_ROJO( x,y) (x+(y*ancho))*3\n",
        "#define PIXEL_VERDE(x,y) PIXEL_ROJO(x,y) + 1\n",
        "#define PIXEL_AZUL( x,y) PIXEL_ROJO(x,y) + 2\n",
        "#define INVERTIR_COLOR(pixel) ({ \\\n",
        "    255 - pixel;\\\n",
        "})\n",
        "\n",
        "__global__ void kernel_img( int ancho, int alto, int *img_O, int *img_R )\n",
        "{\n",
        "  // Calculo las coordenadas del Thread en dos dimensiones.\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  int idy = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "  int iRojo = 0.0;\n",
        "  int iVerde = 0.0;\n",
        "  int iAzul = 0.0;\n",
        "\n",
        "  // Verifico que los Thread, esten dentro de las dimensiones de la imagen.\n",
        "  if(idx>(ancho/2) && idx < ancho && idy < alto )\n",
        "  {\n",
        "    // Calculo el color inverso para el pixel a partir de los componentes.\n",
        "    iRojo = INVERTIR_COLOR(img_O[ PIXEL_ROJO(  idx, idy ) ]);  // Componente Rojo del pixel.\n",
        "    iVerde = INVERTIR_COLOR(img_O[ PIXEL_VERDE( idx, idy ) ]);  // Componente Verde del pixel.\n",
        "    iAzul = INVERTIR_COLOR(img_O[ PIXEL_AZUL(  idx, idy ) ]);  // Componente Azul del pixel.\n",
        "\n",
        "    // Escribo el color del pixel.\n",
        "    img_R[ PIXEL_ROJO(  idx, idy ) ] = iRojo;\n",
        "    img_R[ PIXEL_VERDE( idx, idy ) ] = iVerde;\n",
        "    img_R[ PIXEL_AZUL(  idx, idy ) ] = iAzul;\n",
        "\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "kernel = module.get_function(\"kernel_img\")\n",
        "\n",
        "dim_hilo_x = 32\n",
        "dim_bloque_x = int( (img_ancho+dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "dim_hilo_y = 32\n",
        "dim_bloque_y = int( (img_alto+dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "kernel( numpy.int32(img_ancho), numpy.int32(img_alto), img_O_gpu, img_R_gpu,\n",
        "        block=( dim_hilo_x, dim_hilo_y, 1 ),\n",
        "        grid=(dim_bloque_x, dim_bloque_y,1) )\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "cuda.memcpy_dtoh( img_R_cpu, img_R_gpu )\n",
        "\n",
        "img_O_gpu.free()\n",
        "img_R_gpu.free()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Muestro los atributos de la imagen y como se ve antes del seudo filtro.\n",
        "print(\"Imagen del filtro: \", img_nombre , \" - tipo \" , image.mode , \"- [\" , img_ancho , \", \" , img_alto , \"]\" )\n",
        "# -----------------------------------------------------------------------------\n",
        "# Muestro los atributos de la imagen y como se ve antes del seudo filtro.\n",
        "print(\"Imagen del filtro: \", img_nombre , \" - tipo \" , image.mode , \"- [\" , img_ancho , \", \" , img_alto , \"]\" )\n",
        "print( \"Grilla : [\", dim_bloque_x, \",\", dim_bloque_y, \"], Bloques: [\", dim_hilo_x, \",\", dim_hilo_y, \" ] \"  )\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Muestro la imagen Original el filtro.\n",
        "plt.figure()\n",
        "imgplot=plt.imshow( img_O_cpu )\n",
        "\n",
        "# Muestro la imagen luego de aplicarle el filtro.\n",
        "plt.figure()\n",
        "imgplot=plt.imshow( img_R_cpu )\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting filter_image.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Ejecución y profiling del script\n",
        "\n",
        "Uitlizando nvprof se ejecuta el script y se miden los tiempos de ejecución."
      ],
      "metadata": {
        "id": "igNeiqf9feDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof python filter_image.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0iGeLoe_Mz",
        "outputId": "86dcf92c-6b37-4143-f354-58dec004c4ab"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==29607== NVPROF is profiling process 29607, command: python3 filter_image.py\n",
            "Imagen del filtro:  imagen.jpg  - tipo  RGB - [ 1024 ,  768 ]\n",
            "Imagen del filtro:  imagen.jpg  - tipo  RGB - [ 1024 ,  768 ]\n",
            "Grilla : [ 32 , 24 ], Bloques: [ 32 , 32  ] \n",
            "==29607== Profiling application: python3 filter_image.py\n",
            "==29607== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   63.98%  6.5107ms         1  6.5107ms  6.5107ms  6.5107ms  [CUDA memcpy DtoH]\n",
            "                   35.51%  3.6138ms         2  1.8069ms  1.7625ms  1.8513ms  [CUDA memcpy HtoD]\n",
            "                    0.51%  51.968us         1  51.968us  51.968us  51.968us  kernel_img\n",
            "      API calls:   71.18%  109.59ms         1  109.59ms  109.59ms  109.59ms  cuCtxCreate\n",
            "                   19.60%  30.181ms         1  30.181ms  30.181ms  30.181ms  cuCtxDetach\n",
            "                    5.61%  8.6410ms         1  8.6410ms  8.6410ms  8.6410ms  cuMemcpyDtoH\n",
            "                    2.60%  3.9968ms         2  1.9984ms  1.9317ms  2.0652ms  cuMemcpyHtoD\n",
            "                    0.44%  676.67us         2  338.33us  182.68us  493.99us  cuMemFree\n",
            "                    0.23%  357.94us         1  357.94us  357.94us  357.94us  cuModuleUnload\n",
            "                    0.21%  325.42us         2  162.71us  112.75us  212.67us  cuMemAlloc\n",
            "                    0.07%  108.83us         1  108.83us  108.83us  108.83us  cuModuleLoadDataEx\n",
            "                    0.02%  30.045us         1  30.045us  30.045us  30.045us  cuLaunchKernel\n",
            "                    0.01%  21.387us         2  10.693us     998ns  20.389us  cuCtxPopCurrent\n",
            "                    0.01%  9.9650us         1  9.9650us  9.9650us  9.9650us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.4300us         2  2.2150us     443ns  3.9870us  cuCtxPushCurrent\n",
            "                    0.00%  3.8120us         3  1.2700us     309ns  1.9740us  cuDeviceGetCount\n",
            "                    0.00%  2.8090us         3     936ns     770ns  1.2250us  cuDeviceGetAttribute\n",
            "                    0.00%  1.6990us         2     849ns     740ns     959ns  cuCtxGetDevice\n",
            "                    0.00%  1.3640us         1  1.3640us  1.3640us  1.3640us  cuDeviceComputeCapability\n",
            "                    0.00%  1.3550us         1  1.3550us  1.3550us  1.3550us  cuModuleGetFunction\n",
            "                    0.00%  1.3330us         2     666ns     470ns     863ns  cuDeviceGet\n",
            "                    0.00%     789ns         1     789ns     789ns     789ns  cuFuncSetBlockShape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufDYy0LPmbYH"
      },
      "source": [
        "---\n",
        "# 6 Bibliografía\n",
        "\n",
        "[1]Algoritmo de inversion de colores [Algoritmo](https://www.youtube.com/watch?v=w4GZPcIrvGs)\n",
        "\n",
        "[2] Documentacion Pycuda [WEB](https://documen.tician.de/pycuda/index.html)\n",
        "\n",
        "[3] Repositorio Pycuda [WEB](https://pypi.org/project/pycuda/)\n"
      ]
    }
  ]
}