{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "wxsaxk7FSkmh",
        "3ClX3MgbLn2m",
        "Po1U26ujLs1I",
        "mJxlhR-PHc4M",
        "rBsWMz-fIEaW",
        "feerSPFJI4UV",
        "H-B-4e3gJWp2",
        "B4IHd-IqdvT1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadowRaccoon/PrograConcurrente2023C1/blob/main/TP2/TP2_Parte2_M1\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th1ZsKBrRMrn"
      },
      "source": [
        "# Programacion Concurrente - TP2 - Parte 1\n",
        "\n",
        "Utilizamos 2 prácticas con OpenMP desarrolladas en lenguaje C/C++ nativo en plataforma colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtuoNACar7c-"
      },
      "source": [
        "---\n",
        "## 1.1. Ejercicio 1 - Hola Mundo estilo Programacion Concurrente\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1. Preguntas ejercicio 1:\n",
        "\n",
        "a) Identifique los 3 componentes de openMP en el ejercicio 1.\n",
        "\n",
        "b) Realice pruebas modificando la cantidad de hilos (1, 3, 7). Que conclusiones pudo determinar?.\n",
        "\n",
        "c) ¿Cuál es la diferencia las formas de asignación *static* y *dynamic* en la cláusula *schedule*?, ¿Qué sucede si utiliza *dynamic* en el código?\n",
        "\n",
        "d) En el for: ¿Que sucede con el valor de j, sí se parametriza como lastprivate?\n"
      ],
      "metadata": {
        "id": "apisS7HOLQqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Respuestas:\n",
        "a) Los 3 componentes de openMP son: parallel, single/master y for\n",
        "\n",
        "b) Si ejecutamos el código con el parallel for static con un chunk size de 5 (tal como fue proveído), asigna un bloque de 5 iteraciones a cada hilo por medio de round robin. Con 3 hilos, vemos que el primer hilo tiene más carga, ya que al asignarle el bloque de iteraciones al último hilo, todavía tiene 5 iteraciones pendientes, que le asigna a este. Con 7 hilos por el contrario, quedan hilos sin bloques de iteraciones asignadas debido al chunk size.\n",
        "Al ejecutar el parallel for con dynamic, a los hilos se les asigna un bloque de iteraciones a medida que van terminando las ejecuciones. Haciendo varias pruebas, notamos que muchas veces trabajan muy pocos hilos o hasta uno solo, a pesar de tener 3 o 7 disponibles.\n",
        "\n",
        "c) La asignación por *static* asigna de forma equitativa qué thread va a ejecutar cada bloque de iteraciones al inicio, mientras que en *dynamic* se asignan a medida que un thread termina la ejecución del bloque de iteraciones que le corresponde, esto dependerá de qué recursos están libres en ese momento, y obliga a que los threads deban sincronizarse al momento de tomar una nueva iteración para evitar problemas.\n",
        "\n",
        "d) Se crea una copia de la variable por cada asignación de thread al ejecutar el for, lo que hace que sea privada y exclusiva por cada ejecución de thread.**j** siempre toma la copia del thread que ejecuta la última iteración, siendo la \"última\" iteración la que hubiera correspondido a la última si se hubiera ejecutado de forma secuencial (en este caso la 19).\n",
        "Para el código del ejemplo, el valor de **j** debería ser 5.\n",
        "Sin embargo, notamos que por alguna extraña razón el thread 0, en su ejecución del for, empieza con **j** con un valor basura y no en 0, por lo que en ciertos casos, se produce un resultado erróneo."
      ],
      "metadata": {
        "id": "kPldWcHZtJ4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2. Código Lenguaje C"
      ],
      "metadata": {
        "id": "QQDtKmswLVOm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEbO8EXWm4mL"
      },
      "source": [
        "%%writefile code.cpp\n",
        "\n",
        "// Hola Mundo desde OpenMP, usando c, ejecutado en Colab.\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <omp.h>    // Cabecera OpenMP\n",
        "\n",
        "int main(int argc, char* argv[])\n",
        "{\n",
        "  int i,j=0;\n",
        "  std::cout<<\"Inicio...\"<<std::endl;\n",
        "\n",
        "  //-----------------------------------------------------------------------------------------------\n",
        "  // Region paralela\n",
        "  #pragma omp parallel\n",
        "  {\n",
        "    std::cout<<\"Hola mundo!!!... soy el hilo \" << omp_get_thread_num()<< \", de \"<<  omp_get_num_threads() <<\", procesadores \"<< omp_get_num_procs()<< std::endl;\n",
        "\n",
        "    #pragma omp single\n",
        "    {\n",
        "      std::cout<<\"Hola mundo!!!... soy el hilo \" << omp_get_thread_num()<< \" uno de muchos.\"<< std::endl;\n",
        "    }\n",
        "    #pragma omp master\n",
        "    {\n",
        "      std::cout<<\"Hola mundo!!!... soy el hilo maestro: \" << omp_get_thread_num()<< std::endl;\n",
        "    }\n",
        "\n",
        "    #pragma omp for schedule(static, 5) lastprivate(j)\n",
        "    for(i=0;i<20;i++)\n",
        "    {\n",
        "      j++;\n",
        "      std::cout<<\"Hola mundo!!!... soy el hilo \" << omp_get_thread_num()<< \", itero para i .\"<<i<<\", actualizo j \"<<j<< std::endl;\n",
        "    }\n",
        "  }\n",
        "  // Region paralela\n",
        "  //-----------------------------------------------------------------------------------------------\n",
        "\n",
        "  std::cout<<\"Fin..., con j=\"<<j<<std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2CUqGa2NSPh"
      },
      "source": [
        "### 1.1.3 Compilación de Hola Mundo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLk4a5lTnOEI"
      },
      "source": [
        "!g++ -o hello -fopenmp code.cpp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO--9RYTNe91"
      },
      "source": [
        "### 1.1.4. Ejecución Hola Mundo en OpenMP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98G8IH-NnGHQ"
      },
      "source": [
        "%env OMP_NUM_THREADS=7\n",
        "!./hello"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PQxHPkDdo42"
      },
      "source": [
        "---\n",
        "## 1.2. Ejercicio 2 - Axpy\n",
        "\n",
        "La función Axpy es parte de las bibliotecas BLAS [3]. Ella se encarga de realizar la suma de vectores, con la siguiente ecuación:\n",
        "\n",
        "<center>$Y = \\alpha X + Y$</center>\n",
        "\n",
        "En donde:\n",
        "> $\\alpha$: Es un escala.\n",
        "\n",
        "> $X$: Es el vector origen.\n",
        "\n",
        "> $Y$: Es el vector destino.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Preguntas Ejercicio 2\n",
        "a) Ejecute el ejercicio 1.2.2:\n",
        "\n",
        "    - Con la variable cantidad_N para: 50, 500, 5.000.\n",
        "    - Con los valores hilos_ 2, 4, 6.\n",
        "\n",
        "b) Repita la prueba (a), con ciclos 1, 10, 30. ¿Cuál fue la diferencia?\n",
        "\n",
        "c) ¿Por qué el SpeedUp no mejora a medida que aumentan la cantidad de hilos?\n",
        "\n",
        "d) ¿Qué sucede con la eficiencia a medida que aumentan la cantidad_N?¿Porqué no llega al valor ideal?."
      ],
      "metadata": {
        "id": "wHjoeL_wLguS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Respuestas:\n",
        "a y b)\n",
        "Al ejecutar más ciclos, tarda más porque suma más veces los vectores.\n",
        "Podemos ver que el tiempo de ejecución secuencial es menor al de ejecución paralela y que, al ejecutar más ciclos, aumenta mucho menos que el tiempo de ejecución con OpenMP.\n",
        "Tomamos de ejemplo la ejecución\n",
        "CANTIDAD N 500\n",
        "THREADS: 4\n",
        "\n",
        "1 CICLO\n",
        "Tiempo axpy Sec  : 0.0150204 [ms]\n",
        "\n",
        "10 CICLOS\n",
        "Tiempo axpy Sec  : 0.0901222 [ms]\n",
        "\n",
        "Observamos una diferencia en tiempo de aproximadamente 0.075 ms.\n",
        "\n",
        "1 CICLO\n",
        "Tiempo axpy Omp  : 0.694036 [ms]\n",
        "\n",
        "10 CICLOS\n",
        "Tiempo axpy Omp  : 7.57504 [ms]\n",
        "\n",
        "Observamos una diferencia de aproximadamente 6.9 ms\n",
        "\n",
        "Suponemos que esto ocurre porque el tiempo que deberíamos ahorrarnos paralelizando, es superado por el tiempo de planificación (overhead) que se añade al trabajar con varios hilos. Es decir, este algoritmo no aprovecha la paralelización.\n",
        "\n",
        "c)\n",
        "El SpeedUp se calcula a partir de la siguiente fórmula:\n",
        "SpeedUp=Tiempo_Secuencial/Tiempo_Paralelo\n",
        "\n",
        "En distintas ejecuciones notamos mucha variación en los tiempos de ejecución paralela para una misma cantidad de hilos, mientras que el tiempo de ejecución secuencial siempre se mantiene más o menos estable. Creemos que es porque cambia mucho el tiempo de planificación en cada ejecución.\n",
        "Esto en combinación con lo mencionado anteriormente, nos indica que no se aprovecha el paralelismo, lo cual hace que el tiempo de ejecución paralela sea muy alto por el overhead, por lo cual el speed up, que se calcula a partir de los mismos, no mejora.\n",
        "\n",
        "d)\n",
        "Con los valores indicados en el enunciado, podemos ver que a medida que aumenta la cantidad_N, tiende a mejorar en ciertos casos (aunque con cada ejecución varían mucho los tiempos por lo que es muy dificil de determinar a ciencia cierta), sin embargo, cuando pusimos valores personalizados y pusimos un número muy alto en cantidad_N (500.000), pudimos observar efectivamente la mejora de eficiencia.\n",
        "El valor ideal se calcula suponiendo que el tiempo de ejecución en paralelo es el tiempo de ejecución secuencial dividido por la cantidad de procesadores (en este caso, 2). En la realidad, eso no sucede de esa manera, se produce una mejora para valores muy altos de cantidad_N, pero no necesariamente el doble, ya que hay otros factores que afectan al tiempo de ejecución."
      ],
      "metadata": {
        "id": "bsEJVtnR8-lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Código Lenguaje C"
      ],
      "metadata": {
        "id": "wxsaxk7FSkmh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLE3iWiJsM0G"
      },
      "source": [
        "%%writefile code_axpy.cpp\n",
        "// Axpy con OpenMP, usando c, ejecutado en Colab.\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <sys/time.h>\n",
        "#include <omp.h>    // Cabecera OpenMP\n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "// Macros que miden el tiempo.\n",
        "\n",
        "static double dHashTiempoHistory[3];\n",
        "static struct timeval tv;\n",
        "\n",
        "#define TIEMPO_INI( h )      \\\n",
        "   gettimeofday(&tv,NULL);   \\\n",
        "   dHashTiempoHistory[ h ] = tv.tv_sec + tv.tv_usec/1000000.0;\n",
        "\n",
        "\n",
        "#define TIEMPO_FIN( h )      \\\n",
        "   gettimeofday(&tv,NULL);   \\\n",
        "   dHashTiempoHistory[ h ] = ((tv.tv_sec + tv.tv_usec/1000000.0) - dHashTiempoHistory[ h ]) * 1000; // Devuelvo en milisegundos\n",
        "#define TIEMPO_GET( h ) dHashTiempoHistory[ h ]\n",
        "\n",
        "#define HTH_TOTAL         1\n",
        "#define HTH_AXPY_SEC      2\n",
        "#define HTH_AXPY_OMP      3\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "\n",
        "void axpy( double alfa, vector<double> &X, vector<double> &Y )\n",
        "{\n",
        "  int i;\n",
        "\n",
        "  #pragma omp parallel for\n",
        "  for(i=0;i<Y.size();i++)\n",
        "  {\n",
        "    Y[i] = alfa * X[i] + Y[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "\n",
        "int main(int argc, char* argv[])\n",
        "{\n",
        "  int i,c;\n",
        "  TIEMPO_INI( HTH_TOTAL )\n",
        "\n",
        "  // Leo los parametros.\n",
        "  if( argc != 4 )\n",
        "  {\n",
        "      std::cerr<< \" Error en los parametros de indicar: (alfa), (Tamanio vector), (ciclos ejecucion).\"<<argc<<std::endl;\n",
        "      exit( -1 );\n",
        "  }\n",
        "\n",
        "  float alfa     = atof( argv[1] );\n",
        "  int cantidad_N = atoi( argv[2] );\n",
        "  int ciclos     = atoi( argv[3] );\n",
        "\n",
        "  // --------------------------------------------\n",
        "  // Defino la memoria de los vectores.\n",
        "\n",
        "  vector<double> X( cantidad_N );\n",
        "  vector<double> Y( cantidad_N );\n",
        "\n",
        "  for (int i=0;i<X.size();i++)\n",
        "  {\n",
        "    X[i] = (rand()/(double)RAND_MAX)*0.73;\n",
        "    Y[i] = (rand()/(double)RAND_MAX)*0.71;\n",
        "  }\n",
        "\n",
        "  // --------------------------------------------\n",
        "  // Realizo la función Axpy con OpenMP.\n",
        "\n",
        "  TIEMPO_INI( HTH_AXPY_OMP )\n",
        "\n",
        "  for(c=0;c<ciclos;c++)\n",
        "  {\n",
        "    axpy( alfa, X, Y );\n",
        "  }\n",
        "\n",
        "  TIEMPO_FIN( HTH_AXPY_OMP )\n",
        "\n",
        "  // --------------------------------------------\n",
        "  // Realizo la función Axpy en forma secuencial.\n",
        "\n",
        "  omp_set_num_threads(1);\n",
        "\n",
        "  TIEMPO_INI( HTH_AXPY_SEC )\n",
        "\n",
        "  for(c=0;c<ciclos;c++)\n",
        "  {\n",
        "    axpy( alfa, X, Y );\n",
        "  }\n",
        "\n",
        "  TIEMPO_FIN( HTH_AXPY_SEC )\n",
        "\n",
        "  TIEMPO_FIN( HTH_TOTAL )\n",
        "\n",
        " std::cout<<\"Valores Reales  :\" <<std::endl;\n",
        " std::cout<<\"Tiempo TOTAL     : \"<<TIEMPO_GET(HTH_TOTAL   )<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Sec  : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Omp  : \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<std::endl;\n",
        " std::cout<<\"SpeedUp          : (tiempo Secuencial/tiempo paralelo) : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" / \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Eficiencia       : SpeedUp/nro procesadores            : \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<\" / \"<<omp_get_num_procs()<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))<<std::endl;\n",
        " std::cout<<\"Coste Sec        : nro procesadores*Tiempo             : \"<<1<<\" * \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        " std::cout<<\"Coste Omp        : nro procesadores*Tiempo             : \"<<omp_get_num_procs()<<\" * \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Funcion Overhead : Coste Omp - tiempo Secuencial       : \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<\" - \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))-TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        "\n",
        "\n",
        " std::cout<<std::endl;\n",
        " std::cout<<\"Valores Ideal: \"<<std::endl;\n",
        " TIEMPO_GET(HTH_AXPY_OMP) = TIEMPO_GET(HTH_AXPY_SEC) / omp_get_num_procs();\n",
        " std::cout<<\"Tiempo axpy Sec  : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Omp  : \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" [ms]\"<<std::endl;\n",
        "\n",
        " std::cout<<\"SpeedUp          : (tiempo Secuencial/tiempo paralelo) : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" / \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Eficiencia       : SpeedUp/nro procesadores            : \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<\" / \"<<omp_get_num_procs()<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))<<std::endl;\n",
        " std::cout<<\"Coste Sec        : nro procesadores*Tiempo             : \"<<1<<\" * \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        " std::cout<<\"Coste Omp        : nro procesadores*Tiempo             : \"<<omp_get_num_procs()<<\" * \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Funcion Overhead : Coste Omp - tiempo Secuencial       : \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<\" - \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))-TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        "\n",
        "\n",
        "}\n",
        "// ----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ClX3MgbLn2m"
      },
      "source": [
        "### 1.2.3. Compilación de código C Axpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2PUrH_7tKUS"
      },
      "source": [
        "!g++ -o axpy -fopenmp code_axpy.cpp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po1U26ujLs1I"
      },
      "source": [
        "### 1.2.4. Ejecución Axpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qt_B3jHuHyR",
        "cellView": "form"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "Cantidad_N = 500000#@param {type: \"number\"}\n",
        "Alfa       = 1.0#@param {type: \"number\"}\n",
        "Ciclos = 1 #@param {type:\"slider\", min:1, max:200, step:1}\n",
        "Hilos      = 2#@param {type: \"slider\", min: 1, max: 10}\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "%env OMP_NUM_THREADS=$Hilos\n",
        "!./axpy $Alfa $Cantidad_N $Ciclos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aL0jXjFGn9C"
      },
      "source": [
        "---\n",
        "# Medidas de prestaciones en algoritmos paralelos\n",
        "Las técnicas de HPC buscan reducir los tiempos de ejecución, el tiempo como medida, no alcanza. Dos algoritmos pueden ejecutar en el mismo tiempo, pero uno de ellos usa menos procesadores [6,7].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJxlhR-PHc4M"
      },
      "source": [
        "## SpeedUp\n",
        "Referencia a la ganancia de velocidad que se consigue con un algoritmo paralelo, al resolver el mismo problema con respecto al algoritmo secuencial.\n",
        "\n",
        "<center>$ SpeedUp = \\frac{Tiempo\\_Secuencial}{Tiempo\\_Paralelo} $</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBsWMz-fIEaW"
      },
      "source": [
        "##Eficiencia\n",
        "La eficiencia normaliza el valor del SpeedUp, al dividirlo por la cantidad de procesadores que se utilizaron para alcanzar la ganancia en velocidad. Dando la idea de la porción de tiempo que los procesadores se dedican al trabajo útil.\n",
        "\n",
        "<center>$ Eficiencia = \\frac{SpeedUp}{Nro\\_Procesadores} $</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feerSPFJI4UV"
      },
      "source": [
        "## Coste\n",
        "El coste de un algoritmo paralelo representa el tiempo realizado por todo el sistema en la resolución del problema.\n",
        "\n",
        "<center>$ coste = Nro\\_Procesadores \\times Tiempo\\_Algoritmo$</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-B-4e3gJWp2"
      },
      "source": [
        "## Función Overhead\n",
        "Es la diferencia entre el Coste y el tiempo secuencial. Mientras mayor es la función overhead, peor es el comportamiento del algoritmo paralelo.\n",
        "\n",
        "<center>$ Overhead = {Coste}-{Tiempo\\_Secuencial} $</center>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tk2gqAyQKy_"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4IHd-IqdvT1"
      },
      "source": [
        "---\n",
        "# Bibliografía\n",
        "[1] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n",
        "\n",
        "[3] Biblioteca BLAS: [Referencia](http://www.netlib.org/blas/)\n",
        "\n",
        "[4] F. Almeida, D. Gimenéz, A. Vidal - Introducción a la programación paralela - 2008 - Editorial Parafino.\n",
        "\n",
        "[5] D. Jiménez-González - Introducción a las arquitecturas paralelas. [PDF](http://progc-unlam.com.ar/material-clase/OpenMP-MPI/Introducci%C3%B3n%20a%20la%20Computaci%C3%B3n%20Paralela.pdf)"
      ]
    }
  ]
}